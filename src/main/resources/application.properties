spring.application.name=sc
spring.main.web-application-type=none
spring.config.import=optional:${sc.config.dir}/config[.yaml]
spring.main.banner-mode=off
spring.ai.model.chat=${provider:ollama}
logging.level.root=off

#-------------------------
# Ollama Configuration
#-------------------------
spring.ai.ollama.embedding.options.model=mxbai-embed-large
# Load config in order of precedence:
#   1. CLI argument: --base-url
#   2. Config file property: providers.{provider}.base-url
#   3. Default: http://localhost:11434
spring.ai.ollama.base-url=${base-url:${providers.${spring.ai.model.chat}.base-url:http://localhost:11434}}
spring.ai.ollama.chat.options.model=${providers.ollama.model:mistral-small3.1}
spring.ai.ollama.chat.options.temperature=0.3
spring.ai.ollama.init.pull-model-strategy=never
#-------------------------
# Bedrock Converse Configuration
#-------------------------
spring.ai.bedrock.aws.region=eu-west-1
spring.ai.bedrock.converse.chat.options.model=${providers.bedrock.model:arn:aws:bedrock:eu-west-1:553942258226:application-inference-profile/5w6dzphttz81}
spring.ai.bedrock.converse.chat.options.max-tokens=4096

spring.ai.model.embedding=ollama
spring.ai.chat.memory.repository.jdbc.initialize-schema=always
spring.datasource.hikari.jdbc-url=${chat-memory.jdbc.url:jdbc:hsqldb:${sc.config.dir}/store.db}
spring.datasource.hikari.username=ADMIN
spring.datasource.hikari.password=
sc.config.dir=${SC_CONFIG_DIR:${user.home}/.sc}
sc.vector.simple.store=${sc.config.dir}/vectors
